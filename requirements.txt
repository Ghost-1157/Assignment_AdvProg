System Requirements:

Python Version:
Python 3.8 or higher is recommended.

Operating System:
The application should run on Windows, macOS, and Linux systems.

Python Libraries:

Install these Python libraries using pip:

1) Streamlit:
For building the interactive web interface.
"pip install streamlit"

2) LlamaIndex:
For managing LLM interactions and chat message formatting.
"pip install llama-index"

3) ChromaDB:
For managing a vector store to store queries and responses.
"pip install chromadb"

External Tools and Configuration:

1) LLM Server:
The Ollama server must be running locally or accessible over the network. Install Ollama by following its documentation:
"brew install ollama  # For macOS"

2) ChromaDB Server (Optional):
Ensure ChromaDB is configured and running locally or in a cloud environment if using a distributed setup.

3) API Keys:
If your selected models (e.g., llama, phi, etc.) require API access, ensure you have the necessary keys and credentials.
